// Code generated by pggen. DO NOT EDIT.

package out

import (
	"context"
	"fmt"
	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgconn"
	"github.com/jackc/pgx/v5/pgtype"
	"sync"
)

// Querier is a typesafe Go interface backed by SQL queries.
type Querier interface {
	AlphaNested(ctx context.Context) (string, error)

	AlphaCompositeArray(ctx context.Context) ([]Alpha, error)

	Alpha(ctx context.Context) (string, error)

	Bravo(ctx context.Context) (string, error)
}

var _ Querier = &DBQuerier{}

type DBQuerier struct {
	conn  genericConn
}

// genericConn is a connection like *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
type genericConn interface {
	Query(ctx context.Context, sql string, args ...any) (pgx.Rows, error)
	QueryRow(ctx context.Context, sql string, args ...any) pgx.Row
	Exec(ctx context.Context, sql string, arguments ...any) (pgconn.CommandTag, error)
}

// NewQuerier creates a DBQuerier that implements Querier.
func NewQuerier(conn *pgx.Conn) *DBQuerier {
	_ = conn

	return &DBQuerier{
		conn: conn, 
	}
}

// Alpha represents the Postgres composite type "alpha".
type Alpha struct {
	Key *string `json:"key"`
}


func register(conn *pgx.Conn){
	//
}



/*type compositeField struct {
	name       string                 // name of the field
	typeName   string                 // Postgres type name
	defaultCodec pgtype.Codec // default value to use
}

func (tr *typeResolver) newCompositeValue(name string, fields ...compositeField) pgtype.Codec {
	if _, codec, ok := tr.findCodec(name); ok {
		return codec
	}

	codecs := make([]pgtype.CompositeCodecField, len(fields))
	isBinaryOk := true
	
	for i, field := range fields {
		oid, codec, ok := tr.findCodec(field.typeName)
		if !ok {
			oid = pgtype.UnknownOID
			codec = field.defaultCodec
		}
		isBinaryOk = isBinaryOk && oid != pgtype.UnknownOID
		
		codecs[i] = pgtype.CompositeCodecField{
			Name: field.name,
			Type: &pgtype.Type{Codec: codec, Name: field.typeName, OID: oid},
		}
	}
	// Okay to ignore error because it's only thrown when the number of field
	// names does not equal the number of ValueTranscoders.
	codec := pgtype.CompositeCodec{Fields: codecs}
	// typ, _ := pgtype.NewCompositeTypeValues(name, fs, codecs)
	// if !isBinaryOk {
	// 	return textPreferrer{ValueTranscoder: typ, typeName: name}
	// }
	return codec
}

func (tr *typeResolver) newArrayValue(name, elemName string, defaultVal func() pgtype.ValueTranscoder) pgtype.Codec {
	if _, val, ok := tr.findCodec(name); ok {
		return val
	}
	
	pgType, ok := tr.pgMap.TypeForName(elemName)
	if !ok {
		panic("unhandled")
	}
	
	return &pgtype.ArrayCodec{ElementType: pgType}
}*/

// newAlpha creates a new pgtype.ValueTranscoder for the Postgres
// composite type 'alpha'.
func registernewAlpha() pgtype.Codec {
	return tr.newCompositeValue(
		"alpha",
		compositeField{name: "key", typeName: "text", defaultCodec: &pgtype.TextCodec{}},
	)
}

// newAlphaArray creates a new pgtype.Codec for the Postgres
// '_alpha' array type.
func registernewAlphaArray() pgtype.Codec {
	return tr.newArrayValue("_alpha", "alpha", tr.newAlpha)
}

const alphaNestedSQL = `SELECT 'alpha_nested' as output;`

// AlphaNested implements Querier.AlphaNested.
func (q *DBQuerier) AlphaNested(ctx context.Context) (string, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "AlphaNested")
	rows, err := q.conn.Query(ctx, alphaNestedSQL)
	if err != nil {
		return "", fmt.Errorf("query AlphaNested: %w", err)
	}

	return pgx.CollectExactlyOneRow(rows, func(row pgx.CollectableRow) (string, error) {
		var item string
		if err := row.Scan(
			&item,
		); err != nil {
			return item, fmt.Errorf("failed to scan: %w", err)
		}
		return item, nil
	})
}

const alphaCompositeArraySQL = `SELECT ARRAY[ROW('key')]::alpha[];`

// AlphaCompositeArray implements Querier.AlphaCompositeArray.
func (q *DBQuerier) AlphaCompositeArray(ctx context.Context) ([]Alpha, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "AlphaCompositeArray")
	rows, err := q.conn.Query(ctx, alphaCompositeArraySQL)
	if err != nil {
		return nil, fmt.Errorf("query AlphaCompositeArray: %w", err)
	}

	return pgx.CollectExactlyOneRow(rows, func(row pgx.CollectableRow) ([]Alpha, error) {
		var item []Alpha
		if err := row.Scan(
			&item,
		); err != nil {
			return item, fmt.Errorf("failed to scan: %w", err)
		}
		return item, nil
	})
}

type scanCacheKey struct {
	oid      uint32
	format   int16
	typeName string
}

var (
	plans   = make(map[scanCacheKey]pgtype.ScanPlan, 16)
	plansMu sync.RWMutex
)

func planScan(codec pgtype.Codec, fd pgconn.FieldDescription, target any) pgtype.ScanPlan {
	key := scanCacheKey{fd.DataTypeOID, fd.Format, fmt.Sprintf("%T", target)}
	plansMu.RLock()
	plan := plans[key]
	plansMu.RUnlock()
	if plan != nil {
		return plan
	}
	plan = codec.PlanScan(nil, fd.DataTypeOID, fd.Format, target)
	plansMu.Lock()
	plans[key] = plan
	plansMu.Unlock()
	return plan
}

type ptrScanner[T any] struct {
	basePlan pgtype.ScanPlan
}

func (s ptrScanner[T]) Scan(src []byte, dst any) error {
	if src == nil {
		return nil
	}
	d := dst.(**T)
	*d = new(T)
	return s.basePlan.Scan(src, *d)
}

func planPtrScan[T any](codec pgtype.Codec, fd pgconn.FieldDescription, target *T) pgtype.ScanPlan {
	key := scanCacheKey{fd.DataTypeOID, fd.Format, fmt.Sprintf("*%T", target)}
	plansMu.RLock()
	plan := plans[key]
	plansMu.RUnlock()
	if plan != nil {
		return plan
	}
	basePlan := planScan(codec, fd, target)
	ptrPlan := ptrScanner[T]{basePlan}
	plansMu.Lock()
	plans[key] = plan
	plansMu.Unlock()
	return ptrPlan
}